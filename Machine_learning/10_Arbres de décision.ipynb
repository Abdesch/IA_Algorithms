{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c649e504-9553-41ae-8ed4-4014cbe44ddb",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red; text-align:center; text-decoration:underline;\">Arbres de Décision</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a45f5-21b3-4161-a2cb-cf22f5911957",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green; text-decoration:underline;\">Test 1 : Classification d’un fruit (pomme ou banane)</h2>\n",
    "\n",
    "Dans ce test, un arbre de décision simple est entraîné sur des données représentant des fruits en fonction de leur poids et de leur taille.  \n",
    "L’objectif est de prédire la classe (pomme ou banane) d’un fruit inconnu en utilisant une règle déterministe issue d’un seul arbre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cdd524-453e-4d44-8cd8-7dedaca647c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit de 160g et 8cm est classé comme : pomme\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Étape 1 : Données (poids, taille)\n",
    "# ----------------------------\n",
    "X = np.array([\n",
    "    [180, 8],    # pomme\n",
    "    [200, 7.5],  # pomme\n",
    "    [170, 8.5],  # pomme\n",
    "    [120, 12],   # banane\n",
    "    [130, 13],   # banane\n",
    "    [115, 11.5]  # banane\n",
    "])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])  # 0 = pomme, 1 = banane\n",
    "\n",
    "# ----------------------------\n",
    "# Étape 2 : Création et entraînement de l'arbre\n",
    "# ----------------------------\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# ----------------------------\n",
    "# Étape 3 : Prédiction d’un nouveau fruit\n",
    "# ----------------------------\n",
    "fruit_test = np.array([[160, 8]])  # fruit inconnu\n",
    "prediction = model.predict(fruit_test)\n",
    "\n",
    "# ----------------------------\n",
    "# Étape 4 : Affichage\n",
    "# ----------------------------\n",
    "resultat = \"banane\" if prediction[0] == 1 else \"pomme\"\n",
    "print(f\"Fruit de 160g et 8cm est classé comme : {resultat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8f76c-d0a5-43fd-8163-48253f599f32",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0056b3; text-decoration:underline;\">Résultat</h3>\n",
    "\n",
    "L’arbre de décision a classé le fruit de 160g et 8cm comme une **pomme**.  \n",
    "Cependant, cette prédiction s’appuie sur une seule règle d’arborescence, ce qui peut conduire à des erreurs de généralisation, en particulier pour des cas intermédiaires.  \n",
    "Ce test illustre la vulnérabilité des arbres uniques au **surapprentissage**, notamment en l’absence de mécanismes de régularisation ou d’ensemble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28079d-5848-4d17-88e5-84d69cd8ca1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251da03f-1b06-47f8-b68e-2d1561acf002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a586e5b-ee46-4dde-8b08-6f83be355afc",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green; text-decoration:underline;\">Test 2 : Comparaison avec un modèle Random Forest</h2>\n",
    "\n",
    "Le même échantillon est ensuite testé avec un modèle Random Forest, composé de plusieurs arbres entraînés sur des sous-échantillons aléatoires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08b960c-fcc5-4a64-974b-b46d7708bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbre de décision :  pomme\n",
      "Random Forest     :  banane\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Données : [poids, taille]\n",
    "# ----------------------------\n",
    "X = np.array([\n",
    "    [180, 8],\n",
    "    [200, 7.5],\n",
    "    [170, 8.5],\n",
    "    [120, 12],\n",
    "    [130, 13],\n",
    "    [115, 11.5]\n",
    "])\n",
    "\n",
    "# 0 = pomme, 1 = banane\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# ----------------------------\n",
    "# Modèle 1 : Arbre de décision\n",
    "# ----------------------------\n",
    "tree_model = DecisionTreeClassifier(random_state=0)\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# ----------------------------\n",
    "# Modèle 2 : Forêt aléatoire\n",
    "# ----------------------------\n",
    "forest_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest_model.fit(X, y)\n",
    "\n",
    "# ----------------------------\n",
    "# Tester un fruit inconnu (ex: 150g et 10cm)\n",
    "# ----------------------------\n",
    "fruit_test = np.array([[150, 10]])\n",
    "\n",
    "pred_tree = tree_model.predict(fruit_test)[0]\n",
    "pred_forest = forest_model.predict(fruit_test)[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Affichage\n",
    "# ----------------------------\n",
    "print(\"Arbre de décision : \", \"pomme\" if pred_tree == 0 else \"banane\")\n",
    "print(\"Random Forest     : \", \"pomme\" if pred_forest == 0 else \"banane\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcec00b-6d73-4e53-99a4-a218fd7d569b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0056b3; text-decoration:underline;\">Résultat et Interprétation</h3>\n",
    "\n",
    "L’arbre de décision et le modèle Random Forest ont été appliqués pour prédire la classe d’un fruit caractérisé par un poids de 150g et une taille de 10cm.  \n",
    "L’arbre de décision a classé ce fruit comme une **pomme**, tandis que la Random Forest l’a classé comme une **banane**.\n",
    "\n",
    "Cette divergence met en évidence une limitation classique des arbres de décision uniques : bien qu’interprétables, ils sont sensibles au surapprentissage et peuvent produire des décisions instables, notamment pour les cas ambigus ou proches des frontières de séparation.  \n",
    "À l’inverse, la Random Forest tire parti de l’agrégation de plusieurs arbres diversifiés, ce qui permet de réduire les erreurs dues à une segmentation trop spécifique.  \n",
    "Elle offre ainsi une **meilleure généralisation**, plus robuste face aux variations dans les données, confirmant son avantage sur les modèles simples dans les contextes de classification supervisée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7e1b6-c356-4516-802c-d473296bc1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
